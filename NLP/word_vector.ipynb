{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f10e2f-f971-44cd-817d-e10c3b9d7a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01d3c647-a2da-4d10-a82f-e50237ec897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Dog kill the mouse on running around\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aba09b5f-cc25-4db2-92b6-3b8bdc62adf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog, 'Vector:' True, 'OOV:'True\n",
      "kill, 'Vector:' True, 'OOV:'True\n",
      "the, 'Vector:' True, 'OOV:'True\n",
      "mouse, 'Vector:' True, 'OOV:'True\n",
      "on, 'Vector:' True, 'OOV:'True\n",
      "running, 'Vector:' True, 'OOV:'True\n",
      "around, 'Vector:' True, 'OOV:'True\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token.text}, 'Vector:' {token.has_vector}, 'OOV:'{token.is_oov}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81fbd06b-55c7-4dff-a361-1898a2403d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the vector \n",
    "doc[0].vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a98934-d0b5-4da8-9cd4-23d4bbf4954f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[3].vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4a28f23-31b8-42d9-a840-407bb6ee160b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_token = nlp(\"bread\")\n",
    "base_token.vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66adfd17-70b8-4330-a8aa-8e582565236f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bread <-> bread <-> 1.0\n",
      "sandwich <-> bread <-> 0.26677175290569444\n",
      "burger <-> bread <-> 0.2403758463416168\n",
      "car <-> bread <-> 0.21232414318229098\n",
      "tiger <-> bread <-> 0.41620522485619943\n",
      "human <-> bread <-> 0.17155441719759282\n",
      "wheat <-> bread <-> 0.6217515964505436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12312\\1011719050.py:3: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(f\"{token.text} <-> {base_token.text} <-> {token.similarity(base_token)}\")\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"bread sandwich burger car tiger human wheat\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text} <-> {base_token.text} <-> {token.similarity(base_token)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c17afe48-afa7-4be5-b367-1949dfa800ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(base_word, words_to_compare):\n",
    "    base_token = nlp(base_word)\n",
    "    doc = nlp(words_to_compare)\n",
    "    for token in doc:\n",
    "        print(f\"{token.text} <-> {base_token.text}: \", token.similarity(base_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed08e68-f17a-4f76-a0ca-bd8d38ad9c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samsung <-> apple:  0.10906838556028671\n",
      "brand <-> apple:  0.3254456905518201\n",
      "is <-> apple:  -0.10299302820303877\n",
      "the <-> apple:  -0.21284001514835518\n",
      "most <-> apple:  -0.17056321314349515\n",
      "costly <-> apple:  -0.037262687723069114\n",
      "product <-> apple:  0.604682974047206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12312\\3261933550.py:5: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(f\"{token.text} <-> {base_token.text}: \", token.similarity(base_token))\n"
     ]
    }
   ],
   "source": [
    "similarity(\"apple\", \"samsung brand is the most costly product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca19a817-dbd0-466d-a0b0-73a05318b85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35791e44-9f92-42b8-bd99-ec5d3631ab3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
