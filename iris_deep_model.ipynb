{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d10b6b3b-fa61-43cc-a892-de30dc30e871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "import io\n",
    "import os\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d07ec1c-bfce-411b-bdbf-52426cfe3f1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_l</th>\n",
       "      <th>sepal_w</th>\n",
       "      <th>petal_l</th>\n",
       "      <th>petal_w</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_l  sepal_w  petal_l  petal_w         species\n",
       "0        5.1      3.5      1.4      0.2     Iris-setosa\n",
       "1        4.9      3.0      1.4      0.2     Iris-setosa\n",
       "2        4.7      3.2      1.3      0.2     Iris-setosa\n",
       "3        4.6      3.1      1.5      0.2     Iris-setosa\n",
       "4        5.0      3.6      1.4      0.2     Iris-setosa\n",
       "..       ...      ...      ...      ...             ...\n",
       "145      6.7      3.0      5.2      2.3  Iris-virginica\n",
       "146      6.3      2.5      5.0      1.9  Iris-virginica\n",
       "147      6.5      3.0      5.2      2.0  Iris-virginica\n",
       "148      6.2      3.4      5.4      2.3  Iris-virginica\n",
       "149      5.9      3.0      5.1      1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importing file\n",
    "df = pd.read_csv(r\"C:\\Users\\HP\\Desktop\\deep data\\iris.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63b1ee2d-b291-441e-af5b-3feb9de41217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   sepal_l  150 non-null    float64\n",
      " 1   sepal_w  150 non-null    float64\n",
      " 2   petal_l  150 non-null    float64\n",
      " 3   petal_w  150 non-null    float64\n",
      " 4   species  150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#checking details\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1a14cc1-609a-4ec0-8449-8b106edf5bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal_l', 'sepal_w', 'petal_l', 'petal_w', 'species'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c62ee6d1-2cfd-4de8-8ad8-9a62f0705a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating feature and target\n",
    "x = df[['sepal_l', 'sepal_w', 'petal_l', 'petal_w']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26a9f9a5-bbbc-410e-9c39-a2b487f58bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting categorical variable to numerical variable\n",
    "dummie = pd.get_dummies(df['species'], dtype=int)\n",
    "y = dummie.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f8d3e3a-04f6-4c06-9b21-90b433c89ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ecd8941-2bc2-48ac-976b-9e4a40d89620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a neural network\n",
    "model = Sequential()\n",
    "# First hidden layer with 50 units and ReLU activation\n",
    "model.add(Dense(50, input_dim=x.shape[1], activation='relu'))\n",
    "\n",
    "# Second hidden layer with 25 units and ReLU activation\n",
    "model.add(Dense(25, activation='relu'))\n",
    "\n",
    "# Output layer with the number of classes \n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f89c5f84-f4cd-4479-9ea3-cc333155ce12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4/4 - 2s - loss: 1.5918 - accuracy: 0.3482 - val_loss: 1.5037 - val_accuracy: 0.2895 - 2s/epoch - 450ms/step\n",
      "Epoch 2/1000\n",
      "4/4 - 0s - loss: 1.4081 - accuracy: 0.3482 - val_loss: 1.3310 - val_accuracy: 0.2895 - 139ms/epoch - 35ms/step\n",
      "Epoch 3/1000\n",
      "4/4 - 0s - loss: 1.2758 - accuracy: 0.3482 - val_loss: 1.1967 - val_accuracy: 0.2895 - 121ms/epoch - 30ms/step\n",
      "Epoch 4/1000\n",
      "4/4 - 0s - loss: 1.1613 - accuracy: 0.3482 - val_loss: 1.0928 - val_accuracy: 0.3158 - 121ms/epoch - 30ms/step\n",
      "Epoch 5/1000\n",
      "4/4 - 0s - loss: 1.0726 - accuracy: 0.3929 - val_loss: 1.0122 - val_accuracy: 0.5000 - 111ms/epoch - 28ms/step\n",
      "Epoch 6/1000\n",
      "4/4 - 0s - loss: 0.9927 - accuracy: 0.6250 - val_loss: 0.9447 - val_accuracy: 0.6842 - 114ms/epoch - 28ms/step\n",
      "Epoch 7/1000\n",
      "4/4 - 0s - loss: 0.9326 - accuracy: 0.6518 - val_loss: 0.8849 - val_accuracy: 0.6842 - 116ms/epoch - 29ms/step\n",
      "Epoch 8/1000\n",
      "4/4 - 0s - loss: 0.8771 - accuracy: 0.6518 - val_loss: 0.8271 - val_accuracy: 0.6842 - 119ms/epoch - 30ms/step\n",
      "Epoch 9/1000\n",
      "4/4 - 0s - loss: 0.8235 - accuracy: 0.6607 - val_loss: 0.7744 - val_accuracy: 0.6842 - 116ms/epoch - 29ms/step\n",
      "Epoch 10/1000\n",
      "4/4 - 0s - loss: 0.7816 - accuracy: 0.6607 - val_loss: 0.7368 - val_accuracy: 0.6842 - 115ms/epoch - 29ms/step\n",
      "Epoch 11/1000\n",
      "4/4 - 0s - loss: 0.7535 - accuracy: 0.6964 - val_loss: 0.7033 - val_accuracy: 0.8421 - 129ms/epoch - 32ms/step\n",
      "Epoch 12/1000\n",
      "4/4 - 0s - loss: 0.7239 - accuracy: 0.8571 - val_loss: 0.6733 - val_accuracy: 0.9211 - 221ms/epoch - 55ms/step\n",
      "Epoch 13/1000\n",
      "4/4 - 0s - loss: 0.6967 - accuracy: 0.8482 - val_loss: 0.6459 - val_accuracy: 0.8158 - 111ms/epoch - 28ms/step\n",
      "Epoch 14/1000\n",
      "4/4 - 0s - loss: 0.6729 - accuracy: 0.7946 - val_loss: 0.6208 - val_accuracy: 0.8421 - 123ms/epoch - 31ms/step\n",
      "Epoch 15/1000\n",
      "4/4 - 0s - loss: 0.6508 - accuracy: 0.8304 - val_loss: 0.5959 - val_accuracy: 0.8684 - 108ms/epoch - 27ms/step\n",
      "Epoch 16/1000\n",
      "4/4 - 0s - loss: 0.6292 - accuracy: 0.9286 - val_loss: 0.5757 - val_accuracy: 0.9211 - 107ms/epoch - 27ms/step\n",
      "Epoch 17/1000\n",
      "4/4 - 0s - loss: 0.6122 - accuracy: 0.9643 - val_loss: 0.5575 - val_accuracy: 0.8947 - 107ms/epoch - 27ms/step\n",
      "Epoch 18/1000\n",
      "4/4 - 0s - loss: 0.5949 - accuracy: 0.9375 - val_loss: 0.5390 - val_accuracy: 0.8684 - 102ms/epoch - 26ms/step\n",
      "Epoch 19/1000\n",
      "4/4 - 0s - loss: 0.5775 - accuracy: 0.9643 - val_loss: 0.5218 - val_accuracy: 0.9737 - 105ms/epoch - 26ms/step\n",
      "Epoch 20/1000\n",
      "4/4 - 0s - loss: 0.5622 - accuracy: 0.9286 - val_loss: 0.5059 - val_accuracy: 0.9211 - 103ms/epoch - 26ms/step\n",
      "Epoch 21/1000\n",
      "4/4 - 0s - loss: 0.5488 - accuracy: 0.9018 - val_loss: 0.4909 - val_accuracy: 0.9211 - 106ms/epoch - 26ms/step\n",
      "Epoch 22/1000\n",
      "4/4 - 0s - loss: 0.5355 - accuracy: 0.9018 - val_loss: 0.4778 - val_accuracy: 0.9211 - 132ms/epoch - 33ms/step\n",
      "Epoch 23/1000\n",
      "4/4 - 0s - loss: 0.5237 - accuracy: 0.9107 - val_loss: 0.4654 - val_accuracy: 0.9211 - 110ms/epoch - 28ms/step\n",
      "Epoch 24/1000\n",
      "4/4 - 0s - loss: 0.5120 - accuracy: 0.9375 - val_loss: 0.4547 - val_accuracy: 0.9737 - 108ms/epoch - 27ms/step\n",
      "Epoch 25/1000\n",
      "4/4 - 0s - loss: 0.5028 - accuracy: 0.9732 - val_loss: 0.4446 - val_accuracy: 0.9737 - 106ms/epoch - 27ms/step\n",
      "Epoch 26/1000\n",
      "4/4 - 0s - loss: 0.4922 - accuracy: 0.9464 - val_loss: 0.4340 - val_accuracy: 0.9211 - 119ms/epoch - 30ms/step\n",
      "Epoch 27/1000\n",
      "4/4 - 0s - loss: 0.4814 - accuracy: 0.9196 - val_loss: 0.4242 - val_accuracy: 0.9737 - 135ms/epoch - 34ms/step\n",
      "Epoch 28/1000\n",
      "4/4 - 0s - loss: 0.4717 - accuracy: 0.9375 - val_loss: 0.4150 - val_accuracy: 0.9737 - 106ms/epoch - 27ms/step\n",
      "Epoch 29/1000\n",
      "4/4 - 0s - loss: 0.4622 - accuracy: 0.9554 - val_loss: 0.4062 - val_accuracy: 0.9737 - 115ms/epoch - 29ms/step\n",
      "Epoch 30/1000\n",
      "4/4 - 0s - loss: 0.4522 - accuracy: 0.9643 - val_loss: 0.3970 - val_accuracy: 0.9737 - 128ms/epoch - 32ms/step\n",
      "Epoch 31/1000\n",
      "4/4 - 0s - loss: 0.4434 - accuracy: 0.9732 - val_loss: 0.3882 - val_accuracy: 0.9737 - 113ms/epoch - 28ms/step\n",
      "Epoch 32/1000\n",
      "4/4 - 0s - loss: 0.4328 - accuracy: 0.9464 - val_loss: 0.3803 - val_accuracy: 0.9737 - 105ms/epoch - 26ms/step\n",
      "Epoch 33/1000\n",
      "4/4 - 0s - loss: 0.4246 - accuracy: 0.9375 - val_loss: 0.3721 - val_accuracy: 0.9737 - 110ms/epoch - 27ms/step\n",
      "Epoch 34/1000\n",
      "4/4 - 0s - loss: 0.4160 - accuracy: 0.9375 - val_loss: 0.3644 - val_accuracy: 0.9737 - 128ms/epoch - 32ms/step\n",
      "Epoch 35/1000\n",
      "4/4 - 0s - loss: 0.4085 - accuracy: 0.9375 - val_loss: 0.3571 - val_accuracy: 0.9737 - 106ms/epoch - 26ms/step\n",
      "Epoch 36/1000\n",
      "4/4 - 0s - loss: 0.4036 - accuracy: 0.9286 - val_loss: 0.3504 - val_accuracy: 0.9737 - 116ms/epoch - 29ms/step\n",
      "Epoch 37/1000\n",
      "4/4 - 0s - loss: 0.3947 - accuracy: 0.9375 - val_loss: 0.3439 - val_accuracy: 0.9737 - 113ms/epoch - 28ms/step\n",
      "Epoch 38/1000\n",
      "4/4 - 0s - loss: 0.3877 - accuracy: 0.9732 - val_loss: 0.3381 - val_accuracy: 0.9737 - 110ms/epoch - 28ms/step\n",
      "Epoch 39/1000\n",
      "4/4 - 0s - loss: 0.3801 - accuracy: 0.9732 - val_loss: 0.3316 - val_accuracy: 0.9737 - 109ms/epoch - 27ms/step\n",
      "Epoch 40/1000\n",
      "4/4 - 0s - loss: 0.3735 - accuracy: 0.9732 - val_loss: 0.3247 - val_accuracy: 0.9737 - 104ms/epoch - 26ms/step\n",
      "Epoch 41/1000\n",
      "4/4 - 0s - loss: 0.3650 - accuracy: 0.9732 - val_loss: 0.3176 - val_accuracy: 0.9737 - 116ms/epoch - 29ms/step\n",
      "Epoch 42/1000\n",
      "4/4 - 0s - loss: 0.3579 - accuracy: 0.9643 - val_loss: 0.3115 - val_accuracy: 0.9737 - 133ms/epoch - 33ms/step\n",
      "Epoch 43/1000\n",
      "4/4 - 0s - loss: 0.3504 - accuracy: 0.9732 - val_loss: 0.3059 - val_accuracy: 0.9737 - 108ms/epoch - 27ms/step\n",
      "Epoch 44/1000\n",
      "4/4 - 0s - loss: 0.3458 - accuracy: 0.9643 - val_loss: 0.3016 - val_accuracy: 0.9474 - 112ms/epoch - 28ms/step\n",
      "Epoch 45/1000\n",
      "4/4 - 0s - loss: 0.3390 - accuracy: 0.9732 - val_loss: 0.2956 - val_accuracy: 0.9737 - 103ms/epoch - 26ms/step\n",
      "Epoch 46/1000\n",
      "4/4 - 0s - loss: 0.3302 - accuracy: 0.9732 - val_loss: 0.2896 - val_accuracy: 0.9737 - 104ms/epoch - 26ms/step\n",
      "Epoch 47/1000\n",
      "4/4 - 0s - loss: 0.3267 - accuracy: 0.9643 - val_loss: 0.2861 - val_accuracy: 0.9737 - 110ms/epoch - 28ms/step\n",
      "Epoch 48/1000\n",
      "4/4 - 0s - loss: 0.3216 - accuracy: 0.9464 - val_loss: 0.2793 - val_accuracy: 0.9737 - 149ms/epoch - 37ms/step\n",
      "Epoch 49/1000\n",
      "4/4 - 0s - loss: 0.3150 - accuracy: 0.9821 - val_loss: 0.2755 - val_accuracy: 0.9211 - 128ms/epoch - 32ms/step\n",
      "Epoch 50/1000\n",
      "4/4 - 0s - loss: 0.3093 - accuracy: 0.9732 - val_loss: 0.2722 - val_accuracy: 0.8947 - 114ms/epoch - 28ms/step\n",
      "Epoch 51/1000\n",
      "4/4 - 0s - loss: 0.3029 - accuracy: 0.9732 - val_loss: 0.2647 - val_accuracy: 0.9474 - 112ms/epoch - 28ms/step\n",
      "Epoch 52/1000\n",
      "4/4 - 0s - loss: 0.2950 - accuracy: 0.9821 - val_loss: 0.2598 - val_accuracy: 0.9737 - 107ms/epoch - 27ms/step\n",
      "Epoch 53/1000\n",
      "4/4 - 0s - loss: 0.2910 - accuracy: 0.9643 - val_loss: 0.2554 - val_accuracy: 0.9737 - 109ms/epoch - 27ms/step\n",
      "Epoch 54/1000\n",
      "4/4 - 0s - loss: 0.2853 - accuracy: 0.9643 - val_loss: 0.2493 - val_accuracy: 0.9737 - 115ms/epoch - 29ms/step\n",
      "Epoch 55/1000\n",
      "4/4 - 0s - loss: 0.2774 - accuracy: 0.9821 - val_loss: 0.2460 - val_accuracy: 0.9474 - 112ms/epoch - 28ms/step\n",
      "Epoch 56/1000\n",
      "4/4 - 0s - loss: 0.2729 - accuracy: 0.9732 - val_loss: 0.2422 - val_accuracy: 0.9211 - 118ms/epoch - 29ms/step\n",
      "Epoch 57/1000\n",
      "4/4 - 0s - loss: 0.2676 - accuracy: 0.9732 - val_loss: 0.2362 - val_accuracy: 0.9737 - 116ms/epoch - 29ms/step\n",
      "Epoch 58/1000\n",
      "4/4 - 0s - loss: 0.2631 - accuracy: 0.9732 - val_loss: 0.2319 - val_accuracy: 0.9737 - 100ms/epoch - 25ms/step\n",
      "Epoch 59/1000\n",
      "4/4 - 0s - loss: 0.2567 - accuracy: 0.9821 - val_loss: 0.2271 - val_accuracy: 0.9737 - 130ms/epoch - 32ms/step\n",
      "Epoch 60/1000\n",
      "4/4 - 0s - loss: 0.2503 - accuracy: 0.9821 - val_loss: 0.2236 - val_accuracy: 0.9737 - 117ms/epoch - 29ms/step\n",
      "Epoch 61/1000\n",
      "4/4 - 0s - loss: 0.2456 - accuracy: 0.9732 - val_loss: 0.2201 - val_accuracy: 0.9737 - 127ms/epoch - 32ms/step\n",
      "Epoch 62/1000\n",
      "4/4 - 0s - loss: 0.2409 - accuracy: 0.9732 - val_loss: 0.2154 - val_accuracy: 0.9737 - 125ms/epoch - 31ms/step\n",
      "Epoch 63/1000\n",
      "4/4 - 0s - loss: 0.2358 - accuracy: 0.9821 - val_loss: 0.2109 - val_accuracy: 0.9737 - 122ms/epoch - 30ms/step\n",
      "Epoch 64/1000\n",
      "4/4 - 0s - loss: 0.2309 - accuracy: 0.9821 - val_loss: 0.2072 - val_accuracy: 0.9737 - 112ms/epoch - 28ms/step\n",
      "Epoch 65/1000\n",
      "4/4 - 0s - loss: 0.2259 - accuracy: 0.9821 - val_loss: 0.2043 - val_accuracy: 0.9737 - 116ms/epoch - 29ms/step\n",
      "Epoch 66/1000\n",
      "4/4 - 0s - loss: 0.2219 - accuracy: 0.9732 - val_loss: 0.2016 - val_accuracy: 0.9474 - 117ms/epoch - 29ms/step\n",
      "Epoch 67/1000\n",
      "4/4 - 0s - loss: 0.2178 - accuracy: 0.9732 - val_loss: 0.1961 - val_accuracy: 0.9737 - 123ms/epoch - 31ms/step\n",
      "Epoch 68/1000\n",
      "4/4 - 0s - loss: 0.2121 - accuracy: 0.9821 - val_loss: 0.1925 - val_accuracy: 0.9737 - 113ms/epoch - 28ms/step\n",
      "Epoch 69/1000\n",
      "4/4 - 0s - loss: 0.2088 - accuracy: 0.9821 - val_loss: 0.1892 - val_accuracy: 0.9737 - 122ms/epoch - 31ms/step\n",
      "Epoch 70/1000\n",
      "4/4 - 0s - loss: 0.2032 - accuracy: 0.9821 - val_loss: 0.1874 - val_accuracy: 0.9737 - 118ms/epoch - 29ms/step\n",
      "Epoch 71/1000\n",
      "4/4 - 0s - loss: 0.2015 - accuracy: 0.9732 - val_loss: 0.1850 - val_accuracy: 0.9211 - 118ms/epoch - 29ms/step\n",
      "Epoch 72/1000\n",
      "4/4 - 0s - loss: 0.1989 - accuracy: 0.9821 - val_loss: 0.1794 - val_accuracy: 0.9737 - 116ms/epoch - 29ms/step\n",
      "Epoch 73/1000\n",
      "4/4 - 0s - loss: 0.1925 - accuracy: 0.9732 - val_loss: 0.1776 - val_accuracy: 0.9737 - 121ms/epoch - 30ms/step\n",
      "Epoch 74/1000\n",
      "4/4 - 0s - loss: 0.1886 - accuracy: 0.9732 - val_loss: 0.1734 - val_accuracy: 0.9737 - 119ms/epoch - 30ms/step\n",
      "Epoch 75/1000\n",
      "4/4 - 0s - loss: 0.1848 - accuracy: 0.9821 - val_loss: 0.1707 - val_accuracy: 0.9737 - 115ms/epoch - 29ms/step\n",
      "Epoch 76/1000\n",
      "4/4 - 0s - loss: 0.1845 - accuracy: 0.9732 - val_loss: 0.1723 - val_accuracy: 0.9211 - 112ms/epoch - 28ms/step\n",
      "Epoch 77/1000\n",
      "4/4 - 0s - loss: 0.1809 - accuracy: 0.9732 - val_loss: 0.1650 - val_accuracy: 0.9737 - 120ms/epoch - 30ms/step\n",
      "Epoch 78/1000\n",
      "4/4 - 0s - loss: 0.1745 - accuracy: 0.9821 - val_loss: 0.1623 - val_accuracy: 0.9737 - 118ms/epoch - 30ms/step\n",
      "Epoch 79/1000\n",
      "4/4 - 0s - loss: 0.1707 - accuracy: 0.9821 - val_loss: 0.1609 - val_accuracy: 0.9737 - 120ms/epoch - 30ms/step\n",
      "Epoch 80/1000\n",
      "4/4 - 0s - loss: 0.1676 - accuracy: 0.9732 - val_loss: 0.1602 - val_accuracy: 0.9737 - 113ms/epoch - 28ms/step\n",
      "Epoch 81/1000\n",
      "4/4 - 0s - loss: 0.1675 - accuracy: 0.9732 - val_loss: 0.1581 - val_accuracy: 0.9737 - 118ms/epoch - 29ms/step\n",
      "Epoch 82/1000\n",
      "4/4 - 0s - loss: 0.1634 - accuracy: 0.9732 - val_loss: 0.1528 - val_accuracy: 0.9737 - 116ms/epoch - 29ms/step\n",
      "Epoch 83/1000\n",
      "4/4 - 0s - loss: 0.1603 - accuracy: 0.9821 - val_loss: 0.1505 - val_accuracy: 0.9737 - 117ms/epoch - 29ms/step\n",
      "Epoch 84/1000\n",
      "4/4 - 0s - loss: 0.1578 - accuracy: 0.9821 - val_loss: 0.1482 - val_accuracy: 0.9737 - 119ms/epoch - 30ms/step\n",
      "Epoch 85/1000\n",
      "4/4 - 0s - loss: 0.1544 - accuracy: 0.9821 - val_loss: 0.1478 - val_accuracy: 0.9737 - 110ms/epoch - 28ms/step\n",
      "Epoch 86/1000\n",
      "4/4 - 0s - loss: 0.1526 - accuracy: 0.9732 - val_loss: 0.1532 - val_accuracy: 0.8947 - 111ms/epoch - 28ms/step\n",
      "Epoch 87/1000\n",
      "4/4 - 0s - loss: 0.1534 - accuracy: 0.9732 - val_loss: 0.1457 - val_accuracy: 0.9737 - 114ms/epoch - 29ms/step\n",
      "Epoch 88/1000\n",
      "4/4 - 0s - loss: 0.1495 - accuracy: 0.9732 - val_loss: 0.1402 - val_accuracy: 0.9737 - 117ms/epoch - 29ms/step\n",
      "Epoch 89/1000\n",
      "4/4 - 0s - loss: 0.1462 - accuracy: 0.9821 - val_loss: 0.1384 - val_accuracy: 0.9737 - 116ms/epoch - 29ms/step\n",
      "Epoch 90/1000\n",
      "4/4 - 0s - loss: 0.1460 - accuracy: 0.9732 - val_loss: 0.1398 - val_accuracy: 0.9737 - 114ms/epoch - 29ms/step\n",
      "Epoch 91/1000\n",
      "4/4 - 0s - loss: 0.1445 - accuracy: 0.9732 - val_loss: 0.1375 - val_accuracy: 0.9737 - 112ms/epoch - 28ms/step\n",
      "Epoch 92/1000\n",
      "4/4 - 0s - loss: 0.1387 - accuracy: 0.9821 - val_loss: 0.1337 - val_accuracy: 0.9737 - 115ms/epoch - 29ms/step\n",
      "Epoch 93/1000\n",
      "4/4 - 0s - loss: 0.1432 - accuracy: 0.9821 - val_loss: 0.1317 - val_accuracy: 0.9737 - 119ms/epoch - 30ms/step\n",
      "Epoch 94/1000\n",
      "4/4 - 0s - loss: 0.1390 - accuracy: 0.9732 - val_loss: 0.1373 - val_accuracy: 0.9211 - 112ms/epoch - 28ms/step\n",
      "Epoch 95/1000\n",
      "4/4 - 0s - loss: 0.1347 - accuracy: 0.9732 - val_loss: 0.1323 - val_accuracy: 0.9737 - 109ms/epoch - 27ms/step\n",
      "Epoch 96/1000\n",
      "4/4 - 0s - loss: 0.1310 - accuracy: 0.9732 - val_loss: 0.1282 - val_accuracy: 0.9737 - 117ms/epoch - 29ms/step\n",
      "Epoch 97/1000\n",
      "4/4 - 0s - loss: 0.1323 - accuracy: 0.9821 - val_loss: 0.1257 - val_accuracy: 0.9737 - 118ms/epoch - 29ms/step\n",
      "Epoch 98/1000\n",
      "4/4 - 0s - loss: 0.1287 - accuracy: 0.9821 - val_loss: 0.1268 - val_accuracy: 0.9737 - 111ms/epoch - 28ms/step\n",
      "Epoch 99/1000\n",
      "4/4 - 0s - loss: 0.1273 - accuracy: 0.9732 - val_loss: 0.1279 - val_accuracy: 0.9737 - 174ms/epoch - 44ms/step\n",
      "Epoch 100/1000\n",
      "4/4 - 0s - loss: 0.1246 - accuracy: 0.9732 - val_loss: 0.1228 - val_accuracy: 0.9737 - 121ms/epoch - 30ms/step\n",
      "Epoch 101/1000\n",
      "4/4 - 0s - loss: 0.1234 - accuracy: 0.9821 - val_loss: 0.1205 - val_accuracy: 0.9737 - 116ms/epoch - 29ms/step\n",
      "Epoch 102/1000\n",
      "4/4 - 0s - loss: 0.1258 - accuracy: 0.9821 - val_loss: 0.1192 - val_accuracy: 0.9737 - 116ms/epoch - 29ms/step\n",
      "Epoch 103/1000\n",
      "4/4 - 0s - loss: 0.1212 - accuracy: 0.9821 - val_loss: 0.1216 - val_accuracy: 0.9737 - 112ms/epoch - 28ms/step\n",
      "Epoch 104/1000\n",
      "4/4 - 0s - loss: 0.1206 - accuracy: 0.9732 - val_loss: 0.1233 - val_accuracy: 0.9474 - 111ms/epoch - 28ms/step\n",
      "Epoch 105/1000\n",
      "4/4 - 0s - loss: 0.1182 - accuracy: 0.9732 - val_loss: 0.1180 - val_accuracy: 0.9737 - 114ms/epoch - 29ms/step\n",
      "Epoch 106/1000\n",
      "4/4 - 0s - loss: 0.1191 - accuracy: 0.9821 - val_loss: 0.1144 - val_accuracy: 0.9737 - 116ms/epoch - 29ms/step\n",
      "Epoch 107/1000\n",
      "4/4 - 0s - loss: 0.1174 - accuracy: 0.9821 - val_loss: 0.1151 - val_accuracy: 0.9737 - 112ms/epoch - 28ms/step\n",
      "Epoch 108/1000\n",
      "4/4 - 0s - loss: 0.1156 - accuracy: 0.9732 - val_loss: 0.1164 - val_accuracy: 0.9737 - 110ms/epoch - 27ms/step\n",
      "Epoch 109/1000\n",
      "4/4 - 0s - loss: 0.1124 - accuracy: 0.9732 - val_loss: 0.1122 - val_accuracy: 0.9737 - 114ms/epoch - 29ms/step\n",
      "Epoch 110/1000\n",
      "4/4 - 0s - loss: 0.1155 - accuracy: 0.9821 - val_loss: 0.1103 - val_accuracy: 0.9737 - 112ms/epoch - 28ms/step\n",
      "Epoch 111/1000\n",
      "4/4 - 0s - loss: 0.1137 - accuracy: 0.9821 - val_loss: 0.1107 - val_accuracy: 0.9737 - 110ms/epoch - 27ms/step\n",
      "Epoch 112/1000\n",
      "4/4 - 0s - loss: 0.1099 - accuracy: 0.9732 - val_loss: 0.1121 - val_accuracy: 0.9737 - 110ms/epoch - 27ms/step\n",
      "Epoch 113/1000\n",
      "4/4 - 0s - loss: 0.1086 - accuracy: 0.9732 - val_loss: 0.1115 - val_accuracy: 0.9737 - 110ms/epoch - 28ms/step\n",
      "Epoch 114/1000\n",
      "4/4 - 0s - loss: 0.1078 - accuracy: 0.9732 - val_loss: 0.1122 - val_accuracy: 0.9737 - 114ms/epoch - 28ms/step\n",
      "Epoch 115/1000\n",
      "4/4 - 0s - loss: 0.1070 - accuracy: 0.9732 - val_loss: 0.1084 - val_accuracy: 0.9737 - 115ms/epoch - 29ms/step\n",
      "Epoch 116/1000\n",
      "4/4 - 0s - loss: 0.1054 - accuracy: 0.9821 - val_loss: 0.1067 - val_accuracy: 0.9737 - 115ms/epoch - 29ms/step\n",
      "Epoch 117/1000\n",
      "4/4 - 0s - loss: 0.1097 - accuracy: 0.9732 - val_loss: 0.1078 - val_accuracy: 0.9737 - 109ms/epoch - 27ms/step\n",
      "Epoch 118/1000\n",
      "4/4 - 0s - loss: 0.1029 - accuracy: 0.9821 - val_loss: 0.1036 - val_accuracy: 0.9737 - 112ms/epoch - 28ms/step\n",
      "Epoch 119/1000\n",
      "4/4 - 0s - loss: 0.1045 - accuracy: 0.9821 - val_loss: 0.1025 - val_accuracy: 0.9737 - 111ms/epoch - 28ms/step\n",
      "Epoch 120/1000\n",
      "4/4 - 0s - loss: 0.1023 - accuracy: 0.9821 - val_loss: 0.1052 - val_accuracy: 0.9737 - 110ms/epoch - 28ms/step\n",
      "Epoch 121/1000\n",
      "4/4 - 0s - loss: 0.1031 - accuracy: 0.9732 - val_loss: 0.1103 - val_accuracy: 0.9474 - 106ms/epoch - 27ms/step\n",
      "Epoch 122/1000\n",
      "4/4 - 0s - loss: 0.1018 - accuracy: 0.9732 - val_loss: 0.1034 - val_accuracy: 0.9737 - 104ms/epoch - 26ms/step\n",
      "Epoch 123/1000\n",
      "4/4 - 0s - loss: 0.1000 - accuracy: 0.9821 - val_loss: 0.1009 - val_accuracy: 0.9737 - 110ms/epoch - 27ms/step\n",
      "Epoch 124/1000\n",
      "4/4 - 0s - loss: 0.0998 - accuracy: 0.9821 - val_loss: 0.1005 - val_accuracy: 0.9737 - 122ms/epoch - 31ms/step\n",
      "Epoch 125/1000\n",
      "4/4 - 0s - loss: 0.0983 - accuracy: 0.9821 - val_loss: 0.1018 - val_accuracy: 0.9737 - 117ms/epoch - 29ms/step\n",
      "Epoch 126/1000\n",
      "4/4 - 0s - loss: 0.0991 - accuracy: 0.9732 - val_loss: 0.1033 - val_accuracy: 0.9737 - 99ms/epoch - 25ms/step\n",
      "Epoch 127/1000\n",
      "4/4 - 0s - loss: 0.0970 - accuracy: 0.9732 - val_loss: 0.1018 - val_accuracy: 0.9737 - 100ms/epoch - 25ms/step\n",
      "Epoch 128/1000\n",
      "4/4 - 0s - loss: 0.0957 - accuracy: 0.9732 - val_loss: 0.0975 - val_accuracy: 0.9737 - 106ms/epoch - 26ms/step\n",
      "Epoch 129/1000\n",
      "4/4 - 0s - loss: 0.0961 - accuracy: 0.9821 - val_loss: 0.0967 - val_accuracy: 0.9737 - 102ms/epoch - 26ms/step\n",
      "Epoch 130/1000\n",
      "4/4 - 0s - loss: 0.0976 - accuracy: 0.9732 - val_loss: 0.1017 - val_accuracy: 0.9737 - 103ms/epoch - 26ms/step\n",
      "Epoch 131/1000\n",
      "4/4 - 0s - loss: 0.0950 - accuracy: 0.9732 - val_loss: 0.0980 - val_accuracy: 0.9737 - 102ms/epoch - 25ms/step\n",
      "Epoch 132/1000\n",
      "4/4 - 0s - loss: 0.0961 - accuracy: 0.9732 - val_loss: 0.0946 - val_accuracy: 0.9737 - 99ms/epoch - 25ms/step\n",
      "Epoch 133/1000\n",
      "4/4 - 0s - loss: 0.0930 - accuracy: 0.9821 - val_loss: 0.0957 - val_accuracy: 0.9737 - 105ms/epoch - 26ms/step\n",
      "Epoch 134/1000\n",
      "4/4 - 0s - loss: 0.0928 - accuracy: 0.9821 - val_loss: 0.1005 - val_accuracy: 0.9737 - 100ms/epoch - 25ms/step\n",
      "Epoch 135/1000\n",
      "4/4 - 0s - loss: 0.0943 - accuracy: 0.9643 - val_loss: 0.0976 - val_accuracy: 0.9737 - 106ms/epoch - 26ms/step\n",
      "Epoch 136/1000\n",
      "4/4 - 0s - loss: 0.0950 - accuracy: 0.9732 - val_loss: 0.0921 - val_accuracy: 0.9737 - 168ms/epoch - 42ms/step\n",
      "Epoch 137/1000\n",
      "4/4 - 0s - loss: 0.0901 - accuracy: 0.9821 - val_loss: 0.0963 - val_accuracy: 0.9737 - 131ms/epoch - 33ms/step\n",
      "Epoch 138/1000\n",
      "4/4 - 0s - loss: 0.0906 - accuracy: 0.9732 - val_loss: 0.0993 - val_accuracy: 0.9737 - 106ms/epoch - 27ms/step\n",
      "Epoch 139/1000\n",
      "4/4 - 0s - loss: 0.0911 - accuracy: 0.9732 - val_loss: 0.0953 - val_accuracy: 0.9737 - 100ms/epoch - 25ms/step\n",
      "Epoch 140/1000\n",
      "4/4 - 0s - loss: 0.0882 - accuracy: 0.9732 - val_loss: 0.0901 - val_accuracy: 0.9737 - 105ms/epoch - 26ms/step\n",
      "Epoch 141/1000\n",
      "4/4 - 0s - loss: 0.0918 - accuracy: 0.9821 - val_loss: 0.0883 - val_accuracy: 0.9737 - 107ms/epoch - 27ms/step\n",
      "Epoch 142/1000\n",
      "4/4 - 0s - loss: 0.0907 - accuracy: 0.9821 - val_loss: 0.0932 - val_accuracy: 0.9737 - 107ms/epoch - 27ms/step\n",
      "Epoch 143/1000\n",
      "4/4 - 0s - loss: 0.0887 - accuracy: 0.9732 - val_loss: 0.0959 - val_accuracy: 0.9737 - 106ms/epoch - 26ms/step\n",
      "Epoch 144/1000\n",
      "4/4 - 0s - loss: 0.0925 - accuracy: 0.9643 - val_loss: 0.0970 - val_accuracy: 0.9474 - 103ms/epoch - 26ms/step\n",
      "Epoch 145/1000\n",
      "4/4 - 0s - loss: 0.0855 - accuracy: 0.9821 - val_loss: 0.0868 - val_accuracy: 0.9737 - 103ms/epoch - 26ms/step\n",
      "Epoch 146/1000\n",
      "4/4 - 0s - loss: 0.0901 - accuracy: 0.9821 - val_loss: 0.0860 - val_accuracy: 0.9737 - 105ms/epoch - 26ms/step\n",
      "Epoch 147/1000\n",
      "4/4 - 0s - loss: 0.0914 - accuracy: 0.9821 - val_loss: 0.0862 - val_accuracy: 0.9737 - 104ms/epoch - 26ms/step\n",
      "Epoch 148/1000\n",
      "4/4 - 0s - loss: 0.0877 - accuracy: 0.9821 - val_loss: 0.0911 - val_accuracy: 0.9737 - 108ms/epoch - 27ms/step\n",
      "Epoch 149/1000\n",
      "4/4 - 0s - loss: 0.0852 - accuracy: 0.9732 - val_loss: 0.0877 - val_accuracy: 0.9737 - 100ms/epoch - 25ms/step\n",
      "Epoch 150/1000\n",
      "Restoring model weights from the end of the best epoch: 145.\n",
      "4/4 - 0s - loss: 0.0852 - accuracy: 0.9821 - val_loss: 0.0876 - val_accuracy: 0.9737 - 126ms/epoch - 32ms/step\n",
      "Epoch 150: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x140bc609790>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3,\n",
    "    patience=5,\n",
    "    verbose=2,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,)\n",
    "model.fit(x_train,y_train, validation_data=(x_test,y_test),\n",
    "        callbacks=[monitor],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c914f95-5c86-445f-85b8-c76354117df5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99851733, 0.00148256, 0.        ],\n",
       "       [0.99452204, 0.005478  , 0.00000004],\n",
       "       [0.99755126, 0.0024488 , 0.00000001],\n",
       "       [0.9950177 , 0.00498226, 0.00000005],\n",
       "       [0.9987706 , 0.00122944, 0.        ],\n",
       "       [0.9983617 , 0.00163839, 0.        ],\n",
       "       [0.997638  , 0.00236205, 0.00000001],\n",
       "       [0.99772483, 0.00227521, 0.00000001],\n",
       "       [0.9934263 , 0.00657362, 0.00000011],\n",
       "       [0.9959954 , 0.00400455, 0.00000002],\n",
       "       [0.9988798 , 0.0011202 , 0.        ],\n",
       "       [0.99715275, 0.00284722, 0.00000001],\n",
       "       [0.995928  , 0.00407213, 0.00000003],\n",
       "       [0.99768   , 0.00232001, 0.00000002],\n",
       "       [0.9996335 , 0.00036658, 0.        ],\n",
       "       [0.9996099 , 0.0003901 , 0.        ],\n",
       "       [0.9991985 , 0.00080154, 0.        ],\n",
       "       [0.9981893 , 0.00181071, 0.        ],\n",
       "       [0.9982754 , 0.00172463, 0.        ],\n",
       "       [0.9988403 , 0.00115978, 0.        ],\n",
       "       [0.9958926 , 0.0041075 , 0.00000001],\n",
       "       [0.9982601 , 0.00173987, 0.        ],\n",
       "       [0.9992595 , 0.00074059, 0.        ],\n",
       "       [0.98821664, 0.01178323, 0.00000011],\n",
       "       [0.9937156 , 0.0062844 , 0.00000005],\n",
       "       [0.99043953, 0.00956034, 0.00000009],\n",
       "       [0.9950578 , 0.00494209, 0.00000003],\n",
       "       [0.99820435, 0.00179564, 0.        ],\n",
       "       [0.9981329 , 0.0018672 , 0.        ],\n",
       "       [0.9950517 , 0.00494836, 0.00000004],\n",
       "       [0.99324965, 0.0067502 , 0.00000006],\n",
       "       [0.9958636 , 0.00413635, 0.00000001],\n",
       "       [0.9995679 , 0.00043208, 0.        ],\n",
       "       [0.99965715, 0.00034287, 0.        ],\n",
       "       [0.99472976, 0.00527021, 0.00000004],\n",
       "       [0.99795187, 0.0020481 , 0.00000001],\n",
       "       [0.9987682 , 0.00123186, 0.        ],\n",
       "       [0.9989755 , 0.00102435, 0.        ],\n",
       "       [0.9960741 , 0.00392582, 0.00000004],\n",
       "       [0.99771804, 0.0022819 , 0.00000001],\n",
       "       [0.9984441 , 0.00155606, 0.        ],\n",
       "       [0.95877063, 0.04122682, 0.00000266],\n",
       "       [0.9974616 , 0.00253832, 0.00000002],\n",
       "       [0.99367726, 0.00632271, 0.00000004],\n",
       "       [0.996438  , 0.00356197, 0.00000001],\n",
       "       [0.9930095 , 0.00699033, 0.00000007],\n",
       "       [0.99887955, 0.0011204 , 0.        ],\n",
       "       [0.9970082 , 0.00299177, 0.00000002],\n",
       "       [0.9988662 , 0.00113388, 0.        ],\n",
       "       [0.9976429 , 0.00235713, 0.00000001],\n",
       "       [0.00105277, 0.99240476, 0.00654248],\n",
       "       [0.00202042, 0.98387957, 0.01410006],\n",
       "       [0.00120069, 0.95082986, 0.04796945],\n",
       "       [0.00373724, 0.8048401 , 0.19142261],\n",
       "       [0.00166302, 0.8905516 , 0.1077854 ],\n",
       "       [0.00349631, 0.8770872 , 0.11941653],\n",
       "       [0.00233924, 0.9568489 , 0.04081171],\n",
       "       [0.01509107, 0.9755761 , 0.00933287],\n",
       "       [0.00150308, 0.9758942 , 0.02260274],\n",
       "       [0.00614405, 0.9306571 , 0.06319883],\n",
       "       [0.00611791, 0.9328213 , 0.06106082],\n",
       "       [0.00328349, 0.9714536 , 0.02526292],\n",
       "       [0.00230948, 0.96582663, 0.03186386],\n",
       "       [0.0024016 , 0.86418116, 0.13341735],\n",
       "       [0.01097017, 0.9845435 , 0.00448622],\n",
       "       [0.00151031, 0.9929713 , 0.00551837],\n",
       "       [0.00410556, 0.8493316 , 0.14656276],\n",
       "       [0.00356932, 0.987823  , 0.00860763],\n",
       "       [0.00081838, 0.31651607, 0.68266547],\n",
       "       [0.00370169, 0.9783747 , 0.01792371],\n",
       "       [0.00255302, 0.6171803 , 0.38026667],\n",
       "       [0.00268353, 0.98941165, 0.00790474],\n",
       "       [0.00064278, 0.26791227, 0.73144495],\n",
       "       [0.00233014, 0.91350394, 0.08416602],\n",
       "       [0.00181907, 0.9891196 , 0.00906148],\n",
       "       [0.0015511 , 0.9886972 , 0.00975179],\n",
       "       [0.00120828, 0.9085381 , 0.09025359],\n",
       "       [0.00115217, 0.6679422 , 0.33090565],\n",
       "       [0.00278536, 0.88415986, 0.11305474],\n",
       "       [0.01354924, 0.9830941 , 0.00335665],\n",
       "       [0.00404951, 0.97356176, 0.02238863],\n",
       "       [0.00464977, 0.9842494 , 0.01110072],\n",
       "       [0.00356818, 0.98731726, 0.00911454],\n",
       "       [0.00041833, 0.11823321, 0.8813485 ],\n",
       "       [0.00475272, 0.7937533 , 0.20149398],\n",
       "       [0.0032149 , 0.97746015, 0.01932505],\n",
       "       [0.00147841, 0.9685761 , 0.02994558],\n",
       "       [0.00161494, 0.7764024 , 0.2219825 ],\n",
       "       [0.00416118, 0.98486185, 0.01097694],\n",
       "       [0.00423278, 0.9114581 , 0.08430921],\n",
       "       [0.00386987, 0.82819   , 0.16794011],\n",
       "       [0.00257812, 0.939066  , 0.05835595],\n",
       "       [0.00315512, 0.9775633 , 0.01928138],\n",
       "       [0.01095686, 0.9783481 , 0.01069506],\n",
       "       [0.00397633, 0.92982197, 0.06620181],\n",
       "       [0.00397764, 0.9867498 , 0.00927252],\n",
       "       [0.00374299, 0.9740198 , 0.02223707],\n",
       "       [0.00224271, 0.9844896 , 0.0132676 ],\n",
       "       [0.03352298, 0.96268976, 0.00378725],\n",
       "       [0.00369456, 0.9733076 , 0.02299782],\n",
       "       [0.00002227, 0.00395509, 0.9960226 ],\n",
       "       [0.00011561, 0.02213022, 0.9777542 ],\n",
       "       [0.00002009, 0.01285527, 0.9871246 ],\n",
       "       [0.00007436, 0.02501282, 0.9749128 ],\n",
       "       [0.0000263 , 0.00697787, 0.9929958 ],\n",
       "       [0.00000522, 0.0040297 , 0.9959651 ],\n",
       "       [0.00055709, 0.05002506, 0.94941777],\n",
       "       [0.00001295, 0.01054022, 0.9894467 ],\n",
       "       [0.00002208, 0.0085816 , 0.9913963 ],\n",
       "       [0.00002247, 0.01379985, 0.9861776 ],\n",
       "       [0.00083765, 0.340535  , 0.65862745],\n",
       "       [0.00007218, 0.02683854, 0.97308934],\n",
       "       [0.0000724 , 0.0369552 , 0.9629724 ],\n",
       "       [0.00009177, 0.01276678, 0.98714155],\n",
       "       [0.00006502, 0.00797818, 0.9919569 ],\n",
       "       [0.00012363, 0.03875349, 0.96112275],\n",
       "       [0.00020321, 0.08571032, 0.91408646],\n",
       "       [0.00002635, 0.02919212, 0.97078156],\n",
       "       [0.00000188, 0.00131171, 0.9986863 ],\n",
       "       [0.00010833, 0.03199667, 0.96789485],\n",
       "       [0.00003556, 0.01811034, 0.9818541 ],\n",
       "       [0.00020113, 0.03198729, 0.9678116 ],\n",
       "       [0.00000394, 0.00336775, 0.99662834],\n",
       "       [0.00048223, 0.1766216 , 0.8228962 ],\n",
       "       [0.00011386, 0.05104055, 0.9488455 ],\n",
       "       [0.00011251, 0.094415  , 0.9054725 ],\n",
       "       [0.00091291, 0.30431375, 0.6947734 ],\n",
       "       [0.0012651 , 0.37426227, 0.62447274],\n",
       "       [0.00003304, 0.0085059 , 0.9914611 ],\n",
       "       [0.00022123, 0.20728292, 0.7924957 ],\n",
       "       [0.00001282, 0.01158042, 0.98840666],\n",
       "       [0.0001976 , 0.30648047, 0.6933218 ],\n",
       "       [0.00002922, 0.00698596, 0.9929848 ],\n",
       "       [0.00094872, 0.38580722, 0.6132441 ],\n",
       "       [0.00009284, 0.02997063, 0.9699366 ],\n",
       "       [0.00000836, 0.00842928, 0.99156237],\n",
       "       [0.00005732, 0.01443714, 0.98550546],\n",
       "       [0.00029096, 0.11026137, 0.8894477 ],\n",
       "       [0.00160887, 0.43291798, 0.5654731 ],\n",
       "       [0.00017918, 0.10313803, 0.89668274],\n",
       "       [0.000029  , 0.01014285, 0.9898281 ],\n",
       "       [0.0002779 , 0.14960031, 0.8501217 ],\n",
       "       [0.00011561, 0.02213022, 0.9777542 ],\n",
       "       [0.00002268, 0.00878606, 0.9911912 ],\n",
       "       [0.00002827, 0.00952677, 0.99044496],\n",
       "       [0.0001059 , 0.04554014, 0.9543539 ],\n",
       "       [0.00010102, 0.03449945, 0.96539956],\n",
       "       [0.00028594, 0.11484437, 0.8848697 ],\n",
       "       [0.00017404, 0.04350169, 0.9563243 ],\n",
       "       [0.00062219, 0.1450063 , 0.8543715 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#meking prediction\n",
    "np.set_printoptions(suppress=True)\n",
    "pred = model.predict(x)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e548c282-e4d3-4e1b-95e6-0cd6e24c1a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0874 - accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08744298666715622, 0.9800000190734863]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149eb69b-0cbd-46a2-8fe3-df06e52ef168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
